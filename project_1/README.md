# <center> Анализ резюме из HeadHunter 

## Оглавление
1. [Описание проекта](#Описание-проекта)
2. [Описание данных](#Описание-данных)
3. [Зависимости](#Используемые-зависимости)
4. [Установка проекта](#Установка-проекта)
5. [Использование проекта](#Использование)
6. [Авторы](#Авторы)
7. [Выводы](#выводы)

## Описание проекта

Имеется база резюме, выгруженная с сайта поиска вакансий _hh.ru_.

**Проблема** в том, что часть соискателей не указывают заработную плату при составлении резюме, и это является помехой для рекомендательной системы HeadHunter, которая подбирает соискателям список наиболее подходящих вакансий, а работодателям — список наиболее подходящих специалистов. Для построения успешной модели данные необходимо преобразовать исследовать и очистить.

**Данный проект** направлен на подготовку данных и включает в себя:

* базовый анализ структуры данных
* преобразование данных
* разведывательный анализ
* очистку данных (подробнее с некоторыми используемыми методами очистки можно ознакомиться [здесь](https://github.com/StartrexII/DataCleaning 'GitHub link'))

**О структуре проекта:**
* [data](./data) - папка с исходными табличными данными
* [plotly](./plotly) - папка с графиками, для возможности их просмотра в браузере 
* [Project-1_notebook.ipynb](./Project-1_notebook.ipynb) - jupyter-ноутбук, содержащий основной код проекта, в котором представлена вся работа над данными
* [requirements.txt](./requirements.txt) - файл с версиями используемых модулей, для воспроизводимости кода


## Описание данных
В этом проекте используются данные с сайта _hh.ru_.

Исходный датасет представляет собой набор данных из таблицы с информацией о соискателях. она содержит информацию о 12 признаках, описывающих человека и его достижения.

Файл с данными можно найти [здесь](https://drive.google.com/file/d/1Kb78mAWYKcYlellTGhIjPI-bCcKbGuTn/view 'Google Drive link').

## Используемые зависимости
* Python (3.11.1):
    * [numpy (1.24.1)](https://numpy.org)
    * [pandas (1.5.3)](https://pandas.pydata.org)
    * [matplotlib (3.6.3)](https://matplotlib.org)
    * [seaborn (0.12.2)](https://seaborn.pydata.org)
    * [plotly (5.13.0)](https://plotly.com/python/)

## Установка проекта

* ```
    git clone https://github.com/SkillfactoryDS/DataCleaningProject
    ```
* Открыть директорию  `project_1/`  
                             

## Использование
Вся информация о работе представлена в jupyter-ноутбуке Project-1_notebook.ipynb.
Для запуска кода необходимо скачать исходный датасет (сделать это можно [здесь](https://drive.google.com/file/d/1Kb78mAWYKcYlellTGhIjPI-bCcKbGuTn/view 'Google Drive link')) и установить его в папку `data/`.

## Авторы

* [Егор Орлов](https://vk.com/liquidlogic)

## Выводы

"Сырые" данные необходимо тщательно обрабатывать для возможности проведения грамотного анализа, как аналитического, так и графического и нахождения взаимосвязи между различными признаками для построения хорошей модели, что и было проделано в данной работе.